{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aef002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3524cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d672e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAC3VUyMxsJ6az19WWIJiCGH1lADsWYW8c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97fb3c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lapca\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%pip install google.generativeai\n",
    "import google.generativeai as genai\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "genai.configure(api_key= GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f735dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"AI,\" or Artificial Intelligence, refers to the simulation of human intelligence processes by machines, especially computer systems.  These processes include learning (acquiring information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction.\n",
      "\n",
      "AI is a broad field encompassing many different approaches and techniques, including:\n",
      "\n",
      "* **Machine Learning (ML):**  This involves algorithms that allow systems to learn from data without explicit programming.  Different types of ML include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error).\n",
      "\n",
      "* **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers to analyze data and extract complex patterns.  Deep learning has been particularly successful in areas like image recognition, natural language processing, and speech recognition.\n",
      "\n",
      "* **Natural Language Processing (NLP):** This focuses on enabling computers to understand, interpret, and generate human language.  Applications include chatbots, machine translation, and sentiment analysis.\n",
      "\n",
      "* **Computer Vision:** This involves enabling computers to \"see\" and interpret images and videos.  Applications include object recognition, facial recognition, and image classification.\n",
      "\n",
      "* **Robotics:**  The combination of AI with physical robots allows for the creation of intelligent machines capable of performing tasks in the real world.\n",
      "\n",
      "**Current Capabilities and Limitations:**\n",
      "\n",
      "AI systems have achieved remarkable feats, including beating world champions in chess and Go, developing self-driving cars, and creating realistic artwork and music. However, current AI is still far from achieving human-level intelligence.  Key limitations include:\n",
      "\n",
      "* **Lack of Common Sense Reasoning:**  AI struggles with tasks that require common sense or understanding of the physical world.\n",
      "* **Data Dependency:**  Most AI systems rely heavily on large amounts of training data, and their performance can degrade significantly with biased or incomplete data.\n",
      "* **Explainability (\"Black Box\" Problem):**  Understanding how some complex AI models arrive at their conclusions can be difficult, making it hard to debug errors or trust their decisions.\n",
      "* **Ethical Concerns:**  Bias in training data can lead to discriminatory outcomes, and the potential for misuse of AI raises significant ethical concerns.\n",
      "\n",
      "\n",
      "In short, AI is a rapidly evolving field with tremendous potential to transform many aspects of our lives, but it also presents significant challenges and requires careful consideration of its ethical and societal implications.  The AI we have today is \"narrow\" or \"weak\" AI, meaning it excels at specific tasks but lacks general intelligence.  The development of \"general\" or \"strong\" AI, which would possess human-level intelligence, remains a long-term goal with considerable uncertainty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gemini_llm = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash-latest\")\n",
    "response = gemini_llm.generate_content(\"Tell me about the ai?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edf24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tiktoken\n",
    "import tiktoken \n",
    "def count_token(text):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text, allowed_special= {'<|endoftext|>', '<|endofprompt|>'})\n",
    "\n",
    "    number_of_tokens = len(tokens)\n",
    "\n",
    "    print(\"number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c70cff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 177074\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "total_content = df.tail(10)['noref_content'].str.cat(sep = '/n')\n",
    "print(count_token(total_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e93a716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(question, context = total_content):\n",
    "    prompt = f\"\"\"use the following pieces of context to answer the question at the end. if you don't know the answer,\n",
    "    just say that you don't know , don't make up an answer.\n",
    "\n",
    "      {context}\n",
    "      question : {question}\n",
    "      i prefer answers to be 8-10 sentences long:\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e80325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens: 177149\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query = \"what is model collapse? why does it ocuur and how is it different from catastrophic forgetting?\"\n",
    "prompt = generate_prompt(query)\n",
    "print(count_token(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed619016",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = gemini_llm.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"explain in details how rlhf traning was done for lama2-70B chat model.\"\n",
    "prompt = generate_prompt(query)\n",
    "count_token(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ac9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = gemini_llm.generate_content(prompt)\n",
    "print(response.text)sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570feba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_content = df.tail(10)['noref_content'].str.cat(sep='/n')\n",
    "print(count_token(total_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9d2fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lapca\\AppData\\Local\\Temp\\ipykernel_12368\\2392124743.py:9: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  bge_embeddings = HuggingFaceBgeEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "#%pip install langchain\n",
    "#%pip install -U langchain-community\n",
    "#%pip install sentence-transformers\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e5ee30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>references</th>\n",
       "      <th>content</th>\n",
       "      <th>noref_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2206.02336</td>\n",
       "      <td>2206.02336</td>\n",
       "      <td>Making Large Language Models Better Reasoners ...</td>\n",
       "      <td>Few-shot learning is a challenging task that r...</td>\n",
       "      <td>http://arxiv.org/pdf/2206.02336</td>\n",
       "      <td>['Yifei Li' 'Zeqi Lin' 'Shizhuo Zhang' 'Qiang ...</td>\n",
       "      <td>['cs.CL' 'cs.AI']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>20220606</td>\n",
       "      <td>20230524</td>\n",
       "      <td>\\n\\n* D. Andor, L. He, K. Lee, and E. Pitler (...</td>\n",
       "      <td># Making Large Language Models Better Reasoner...</td>\n",
       "      <td># Making Large Language Models Better Reasoner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2206.04615</td>\n",
       "      <td>2206.04615</td>\n",
       "      <td>Beyond the Imitation Game: Quantifying and ext...</td>\n",
       "      <td>Language models demonstrate both quantitative ...</td>\n",
       "      <td>http://arxiv.org/pdf/2206.04615</td>\n",
       "      <td>['Aarohi Srivastava' 'Abhinav Rastogi' 'Abhish...</td>\n",
       "      <td>['cs.CL' 'cs.AI' 'cs.CY' 'cs.LG' 'stat.ML']</td>\n",
       "      <td>27 pages, 17 figures + references and appendic...</td>\n",
       "      <td>Transactions on Machine Learning Research, May...</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>20220609</td>\n",
       "      <td>20230612</td>\n",
       "      <td>\\n\\n* Wikiquote et al. (2021) Wikiquote, russi...</td>\n",
       "      <td># Beyond the Imitation Game: Quantifying and e...</td>\n",
       "      <td># Beyond the Imitation Game: Quantifying and e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2206.05229</td>\n",
       "      <td>2206.05229</td>\n",
       "      <td>Measuring the Carbon Intensity of AI in Cloud ...</td>\n",
       "      <td>By providing unprecedented access to computati...</td>\n",
       "      <td>http://arxiv.org/pdf/2206.05229</td>\n",
       "      <td>['Jesse Dodge' 'Taylor Prewitt' 'Remi Tachet D...</td>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>In ACM Conference on Fairness, Accountability,...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>20220610</td>\n",
       "      <td>20220610</td>\n",
       "      <td>\\n\\n* (1)\\n* Anthony et al. (2020) Lasse F. Wo...</td>\n",
       "      <td>[MISSING_PAGE_EMPTY:1]\\n\\nIntroduction\\n\\nClim...</td>\n",
       "      <td>[MISSING_PAGE_EMPTY:1]\\n\\nIntroduction\\n\\nClim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2206.05802</td>\n",
       "      <td>2206.05802</td>\n",
       "      <td>Self-critiquing models for assisting human eva...</td>\n",
       "      <td>We fine-tune large language models to write na...</td>\n",
       "      <td>http://arxiv.org/pdf/2206.05802</td>\n",
       "      <td>['William Saunders' 'Catherine Yeh' 'Jeff Wu' ...</td>\n",
       "      <td>['cs.CL' 'cs.LG']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>20220612</td>\n",
       "      <td>20220614</td>\n",
       "      <td>(RLHP) has become more common [1, 2, 3, 4], d...</td>\n",
       "      <td># Self-critiquing models for assisting human e...</td>\n",
       "      <td># Self-critiquing models for assisting human e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2206.06336</td>\n",
       "      <td>2206.06336</td>\n",
       "      <td>Language Models are General-Purpose Interfaces</td>\n",
       "      <td>Foundation models have received much attention...</td>\n",
       "      <td>http://arxiv.org/pdf/2206.06336</td>\n",
       "      <td>['Yaru Hao' 'Haoyu Song' 'Li Dong' 'Shaohan Hu...</td>\n",
       "      <td>['cs.CL']</td>\n",
       "      <td>32 pages. The first three authors contribute e...</td>\n",
       "      <td>None</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>20220613</td>\n",
       "      <td>20220613</td>\n",
       "      <td>\\n\\n* Agrawal et al. (2019) Harsh Agrawal, Kar...</td>\n",
       "      <td># Language Models are General-Purpose Interfac...</td>\n",
       "      <td># Language Models are General-Purpose Interfac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          doi          id                                              title  \\\n",
       "0  2206.02336  2206.02336  Making Large Language Models Better Reasoners ...   \n",
       "1  2206.04615  2206.04615  Beyond the Imitation Game: Quantifying and ext...   \n",
       "2  2206.05229  2206.05229  Measuring the Carbon Intensity of AI in Cloud ...   \n",
       "3  2206.05802  2206.05802  Self-critiquing models for assisting human eva...   \n",
       "4  2206.06336  2206.06336     Language Models are General-Purpose Interfaces   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Few-shot learning is a challenging task that r...   \n",
       "1  Language models demonstrate both quantitative ...   \n",
       "2  By providing unprecedented access to computati...   \n",
       "3  We fine-tune large language models to write na...   \n",
       "4  Foundation models have received much attention...   \n",
       "\n",
       "                            source  \\\n",
       "0  http://arxiv.org/pdf/2206.02336   \n",
       "1  http://arxiv.org/pdf/2206.04615   \n",
       "2  http://arxiv.org/pdf/2206.05229   \n",
       "3  http://arxiv.org/pdf/2206.05802   \n",
       "4  http://arxiv.org/pdf/2206.06336   \n",
       "\n",
       "                                             authors  \\\n",
       "0  ['Yifei Li' 'Zeqi Lin' 'Shizhuo Zhang' 'Qiang ...   \n",
       "1  ['Aarohi Srivastava' 'Abhinav Rastogi' 'Abhish...   \n",
       "2  ['Jesse Dodge' 'Taylor Prewitt' 'Remi Tachet D...   \n",
       "3  ['William Saunders' 'Catherine Yeh' 'Jeff Wu' ...   \n",
       "4  ['Yaru Hao' 'Haoyu Song' 'Li Dong' 'Shaohan Hu...   \n",
       "\n",
       "                                    categories  \\\n",
       "0                            ['cs.CL' 'cs.AI']   \n",
       "1  ['cs.CL' 'cs.AI' 'cs.CY' 'cs.LG' 'stat.ML']   \n",
       "2                                    ['cs.LG']   \n",
       "3                            ['cs.CL' 'cs.LG']   \n",
       "4                                    ['cs.CL']   \n",
       "\n",
       "                                             comment  \\\n",
       "0                                               None   \n",
       "1  27 pages, 17 figures + references and appendic...   \n",
       "2  In ACM Conference on Fairness, Accountability,...   \n",
       "3                                               None   \n",
       "4  32 pages. The first three authors contribute e...   \n",
       "\n",
       "                                         journal_ref primary_category  \\\n",
       "0                                               None            cs.CL   \n",
       "1  Transactions on Machine Learning Research, May...            cs.CL   \n",
       "2                                               None            cs.LG   \n",
       "3                                               None            cs.CL   \n",
       "4                                               None            cs.CL   \n",
       "\n",
       "   published   updated                                         references  \\\n",
       "0   20220606  20230524  \\n\\n* D. Andor, L. He, K. Lee, and E. Pitler (...   \n",
       "1   20220609  20230612  \\n\\n* Wikiquote et al. (2021) Wikiquote, russi...   \n",
       "2   20220610  20220610  \\n\\n* (1)\\n* Anthony et al. (2020) Lasse F. Wo...   \n",
       "3   20220612  20220614   (RLHP) has become more common [1, 2, 3, 4], d...   \n",
       "4   20220613  20220613  \\n\\n* Agrawal et al. (2019) Harsh Agrawal, Kar...   \n",
       "\n",
       "                                             content  \\\n",
       "0  # Making Large Language Models Better Reasoner...   \n",
       "1  # Beyond the Imitation Game: Quantifying and e...   \n",
       "2  [MISSING_PAGE_EMPTY:1]\\n\\nIntroduction\\n\\nClim...   \n",
       "3  # Self-critiquing models for assisting human e...   \n",
       "4  # Language Models are General-Purpose Interfac...   \n",
       "\n",
       "                                       noref_content  \n",
       "0  # Making Large Language Models Better Reasoner...  \n",
       "1  # Beyond the Imitation Game: Quantifying and e...  \n",
       "2  [MISSING_PAGE_EMPTY:1]\\n\\nIntroduction\\n\\nClim...  \n",
       "3  # Self-critiquing models for assisting human e...  \n",
       "4  # Language Models are General-Purpose Interfac...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%pip install datasets\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"deep-learning-analytics/arxiv_small_nougat\")\n",
    "\n",
    "df = Dataset.to_pandas(ds['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023b029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2206.02336, 2206.04615, 2206.05229, 2206.05802, 2206.06336, 2206.07635, 2206.14858, 2207.0056, 2207.04672, 2207.05221, 2207.05608, 2207.09983, 2207.10551, 2208.02294, 2208.03299, 2208.11663, 2208.14271, 2209.03143, 2209.07686, 2209.07753, 2209.07858, 2209.14375, 2209.15003, 2210.01241, 2210.02406, 2210.02414, 2210.02875, 2210.02969, 2210.0307, 2210.03078, 2210.0335, 2210.03493, 2210.03629, 2210.03945, 2210.05359, 2210.06245, 2210.07316, 2210.07382, 2210.077, 2210.09261, 2210.11399, 2210.11416, 2210.12283, 2210.13236, 2211.00053, 2211.00295, 2211.01786, 2211.0191, 2211.02001, 2211.04325, 2211.051, 2211.08264, 2211.08411, 2211.09085, 2211.0911, 2211.0926, 2211.10435, 2211.11736, 2212.00193, 2212.06817, 2212.08073, 2212.08286, 2212.0841, 2212.09689, 2212.10403, 2212.1056, 2212.12017, 2212.14882, 2301.00303, 2301.03728, 2301.07597, 2301.08653, 2301.09211, 2301.10226, 2301.11305, 2301.12867, 2301.13196, 2301.13688, 2302.04166, 2302.04761, 2302.07459, 2302.07736, 2302.07842, 2302.07867, 2302.08582, 2302.0927, 2302.13971, 2303.11156, 2303.12712, 2303.15056, 2303.17651, 2304.01196, 2304.01373, 2304.03277, 2304.06364, 2304.07327, 2304.09542, 2304.12298, 2304.14178, 2305.02301, 2305.03047, 2305.098, 2305.09941, 2305.11206, 2305.15717, 2305.17493, 2306.05949, 2307.09288]\n"
     ]
    }
   ],
   "source": [
    "paper_ids = df['doi'].unique().tolist()\n",
    "print(paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27e2cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "keep_cols = ['id','title','authors','summary','source','published','noref_content']\n",
    "df_subset = df[keep_cols]\n",
    "df_subset = df_subset.dropna()\n",
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c90b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader\n",
    "loader = DataFrameLoader(df_subset , page_content_column=\"noref_content\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4660906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "                  \n",
    "text_splitter =  RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba12b906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Split Docs:  9790\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Split Docs: \", len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2d5983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lapca\\AppData\\Local\\Temp\\ipykernel_12368\\1872407943.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=\"./chroma_db\", embedding_function=bge_embeddings)\n"
     ]
    }
   ],
   "source": [
    "### Load to a database - Run this for the first time to create the Db file\n",
    "\n",
    "#%pip install -U langchain-community\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(split_docs, bge_embeddings, persist_directory=\"./chroma_db\")\n",
    "\n",
    "## Load from a database\n",
    "db = Chroma(persist_directory=\"./chroma_db\", embedding_function=bge_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974de161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched doc 1 is : We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: annotators write a prompt that they believe can elicit unsafe behavior, and then compare multiple model responses to the prompts, selecting the response that is safest according to a set of guidelines. We then use the human preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to sample from the model during the RLHF stage. /n ========\n",
      "Matched doc 2 is : We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: annotators write a prompt that they believe can elicit unsafe behavior, and then compare multiple model responses to the prompts, selecting the response that is safest according to a set of guidelines. We then use the human preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to sample from the model during the RLHF stage. /n ========\n",
      "Matched doc 3 is : We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: annotators write a prompt that they believe can elicit unsafe behavior, and then compare multiple model responses to the prompts, selecting the response that is safest according to a set of guidelines. We then use the human preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to sample from the model during the RLHF stage. /n ========\n",
      "Matched doc 4 is : Christiano et al., 2017; Warnell et al., 2018) aims to overcome these limitations by using human preferences as an evaluation metric and as an objective function to optimize the language model. Using RLHF allows LMs to be more closely aligned with complex human preferences and values which are difficult to capture by hard-coded reward functions. /n ========\n"
     ]
    }
   ],
   "source": [
    "# text retriver\n",
    "query = 'what is RLHF? when can id be used?'\n",
    "matched_docs = db.similarity_search(query, k = 8)\n",
    "\n",
    "#print results\n",
    "for index, value in enumerate(matched_docs):\n",
    "    pos = index+1\n",
    "    if index <=3:\n",
    "        print(f\"Matched doc {pos} is :\", matched_docs[index].page_content, \"/n ========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b586277",
   "metadata": {},
   "source": [
    "# add answer generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24c8132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    " if you don't know the answer, just say that you don't know , don't try to make up the answer.\n",
    " \n",
    " {context}\n",
    " Question: {question}\n",
    " I prefer answers to be 8-10 sentences long:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template= prompt_template, input_variables= [\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d362375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain_google_genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_google_genai) (0.3.55)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_google_genai) (2.11.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.24.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.39.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.29.4)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.3.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lapca\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain_google_genai) (1.3.1)\n",
      "Downloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 6.4 MB/s eta 0:00:00\n",
      "Installing collected packages: filetype, google-ai-generativelanguage, langchain_google_genai\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
      "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
      "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain_google_genai-2.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9184a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "retriver = db.as_retriever()\n",
    "retriver.search_kwargs['k']= 8\n",
    "\n",
    "model =  ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "chain_type_kwargs = {\"prompt\":prompt}\n",
    "qa = RetrievalQA.from_chain_type(llm = model , chain_type = \"stuff\", retriever = retriver , chain_type_kwargs = chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0373353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: RLHF (Reinforcement Learning from Human Feedback) offers several key benefits in training language models.  It allows these models to better align with complex human preferences and values, which are difficult to encode through traditional, hard-coded reward functions.  This is achieved by using human feedback as both an evaluation metric and an objective function during the optimization process.  Essentially, RLHF trains models to generate text that humans find more desirable, helpful, and aligned with their intentions.  Compared to earlier methods, RLHF has shown significant improvements, making techniques like context distillation less impactful.  Furthermore, studies indicate that for simpler tasks like coreference resolution, especially with gendered pronouns, additional RLHF training may not yield further benefits because the model achieves a high level of performance early on. However, for more complex tasks, RLHF plays a crucial role in refining model outputs to be more nuanced and aligned with human expectations.  This makes RLHF a powerful tool for developing language models that are more useful and less prone to generating undesirable or harmful content.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the benefit of RLHf\"\n",
    "result = qa.invoke({\"query\": query})\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79dca4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Model collapse is a degenerative process in generative models where generated data contaminates the training set of subsequent models, leading to a misrepresentation of the original data distribution.  This occurs over generations, with each new model trained on increasingly polluted data, exacerbating the issue.  Two forms exist: early collapse, characterized by information loss in the tails of the distribution, and late collapse, where distinct modes become entangled, resulting in a low-variance distribution dissimilar to the original.  It's driven by two main causes, one primary and one secondary, with the primary cause being essential for the process to continue beyond the first generation.  Unlike catastrophic forgetting, which involves a single model losing previously learned information, model collapse involves multiple generations of models.  In model collapse, models don't forget, but rather misinterpret the data distribution due to the increasing prevalence of generated data in their training sets.  This reinforces their own flawed understanding, leading to a progressive deviation from reality.  Further mathematical details explaining the underlying mechanisms and quantifying the divergence rate are typically explored in subsequent sections of research papers on this topic.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is model collapse ? why does it occur and how is it different from catastrophic forgetting?\"\n",
    "result = qa.invoke({\"query\":query})\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9818499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Llama 2-Chat's RLHF training involved two key stages after initial supervised fine-tuning: rejection sampling and Proximal Policy Optimization (PPO).  First, a few thousand safe demonstrations were used for supervised fine-tuning, enabling the model to generalize and produce detailed safe responses.  Then, the model transitioned fully to RLHF to refine its responses and enhance nuance.  Two distinct reward models were employed: one for helpfulness and another for safety, mitigating the potential trade-off between these qualities.  These reward models provided scalar scores based on the prompt and model response, guiding the RLHF process.  Rejection sampling and PPO iteratively refined the model, aligning it with human preferences.  Throughout the RLHF stage, iterative reward modeling data collection ensured the reward models remained within distribution. This approach aimed to improve both the safety and helpfulness of the model's responses while increasing robustness against jailbreak attempts.\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain in details how was rlhf training done for llama2 -70B chat model?\"\n",
    "result = qa.invoke({\"query\" :query})\n",
    "\n",
    "print(\"Answer:\", result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af0b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761a1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e5c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a082fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b83c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
